{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7yYE7X7_mgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, pickle, re, sklearn, string\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6e78a35d-7cab-4fe1-bec9-9b7484ab806b",
        "id": "177cZi2OjAWT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')# Download text data sets, including stop words\n",
        "from nltk.corpus import stopwords # Import the stop word list\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# Download the punkt tokenizer for sentence splitting\n",
        "import nltk.data\n",
        "nltk.download('punkt')   \n",
        "\n",
        "# Load the punkt tokenizer\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "class Creat_vocabulary():\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.sentences = []\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = {}\n",
        "    self.idx_pairs = []\n",
        "    self.all_voc = []\n",
        "    self.negative_pairs = []\n",
        "    \n",
        "    \n",
        "  def get_sentence(self):\n",
        "    \n",
        "      return self.sentences\n",
        "    \n",
        "    \n",
        "  def get_word2idx(self):\n",
        "    \n",
        "      return self.word2idx\n",
        "  \n",
        "  \n",
        "  def get_idx2word(self):\n",
        "    \n",
        "      return self.idx2word\n",
        "  \n",
        "  \n",
        "  def get_idx_pairs(self):\n",
        "    \n",
        "      return self.idx_pairs\n",
        "    \n",
        "  def expand(self,ListofList):\n",
        "    \n",
        "    for ll in ListofList:\n",
        "      for l in ll:\n",
        "        self.all_voc.append(l)\n",
        "    return self.all_voc   \n",
        "  \n",
        "\n",
        "  # Define a function to split a review into parsed sentences\n",
        "  def review_to_sentences( self, review, tokenizer, remove_stopwords=False ):\n",
        "      # Function to split a review into parsed sentences. Returns a \n",
        "      # list of sentences, where each sentence is a list of words\n",
        "    \n",
        "      # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
        "      raw_sentences = tokenizer.tokenize(review.strip())\n",
        "    \n",
        "    \n",
        "      # 2. Loop over each sentence\n",
        "      sentences = []\n",
        "      for raw_sentence in raw_sentences:\n",
        "      \n",
        "          # If a sentence is empty, skip it\n",
        "          if len(raw_sentence) > 0:\n",
        "          \n",
        "              # Otherwise, call review_to_wordlist to get a list of words\n",
        "              sentences.append( self.review_to_wordlist( raw_sentence,remove_stopwords ))\n",
        "    \n",
        "      # Return List os List of Tokens in a sentence\n",
        "      return sentences\n",
        "\n",
        "  \n",
        "  def review_to_wordlist(self, review, remove_stopwords=False ):\n",
        "  \n",
        "    # Function to convert a document to a sequence of words,\n",
        "    # optionally removing stop words. Returns a list of words.\n",
        "\n",
        "    # 1. Remove HTML\n",
        "    review_text = BeautifulSoup(review).get_text()\n",
        "\n",
        "    # 2. Remove non-letters\n",
        "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "\n",
        "    # 3. Convert words to lower case and split them\n",
        "    words = review_text.lower().split()\n",
        "\n",
        "    # 4. Optionally remove stop words (false by default)\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in stops]\n",
        "\n",
        "    # 5. Return a list of words\n",
        "    return(words)\n",
        "\n",
        "\n",
        "  def reviews_to_Words(self,data, tokenizer):\n",
        "  \n",
        "    sentences = []  # Initialize an empty list of sentences\n",
        "\n",
        "    print (\"Parsing sentences from training set\")\n",
        "  \n",
        "    for review in data[\"review\"]:\n",
        "      self.sentences += self.review_to_sentences(review, tokenizer)\n",
        "  \n",
        "    return self.sentences\n",
        "  \n",
        " \n",
        "  \n",
        "  def dictionary(self, tokenizer ):\n",
        "    \n",
        "    vocabulary = []\n",
        "    for sentence in self.sentences:\n",
        "      for token in sentence:\n",
        "          if token not in vocabulary:\n",
        "              vocabulary.append(token)\n",
        "\n",
        "    self.word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "    self.idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "\n",
        "    vocabulary_size = len(vocabulary)\n",
        "    \n",
        "    return vocabulary_size, self.word2idx, self.idx2word\n",
        "  \n",
        "  def skip_contex_tuple(self,context_size):\n",
        "    \n",
        "    \n",
        "    # changing context_size to window size\n",
        "    if(context_size % 2 != 0):\n",
        "      window_size = int(context_size + 1)//2\n",
        "    else:\n",
        "      window_size = int(context_size)//2\n",
        "  \n",
        "    #find context words around each word in a sentence and then coolect it in a list using vocab index in our dic\n",
        "    for sentence in self.sentences:\n",
        "      \n",
        "      \n",
        "      indices = [self.word2idx[word] for word in sentence]\n",
        "      \n",
        "      # for each word, threated as center word\n",
        "      for center_word_pos in range(len(indices)):\n",
        "        tup =[]\n",
        "        \n",
        "        for w in range(-window_size, window_size):\n",
        "          cntx_pos = center_word_pos + w \n",
        "          \n",
        "\n",
        "          if cntx_pos <=0 or cntx_pos>=len(indices) or cntx_pos == center_word_pos:\n",
        "\n",
        "            continue\n",
        "            \n",
        "          tup.append(self.word2idx[sentence[cntx_pos]])\n",
        "            \n",
        "        # for each window position\n",
        "        #tup = [sentence[center_word_pos + w ] for w in range(-window_size, window_size) if center_word_pos + w > 0 and center_word_pos + w <= len(indices) and center_word_pos  != center_word_pos + w ]\n",
        "\n",
        "        self.idx_pairs.append((indices[center_word_pos], tup,1))\n",
        "\n",
        "    self.idx_pairs = np.array(self.idx_pairs) # it will be useful to have this as numpy array\n",
        "    \n",
        "    return self.idx_pairs\n",
        "  \n",
        "  \n",
        "  def get_negatives(self,idx_pairs, sampling_weights, K):\n",
        "    \n",
        "    all_negatives = []\n",
        "    \n",
        "    generator = RandomGenerator(sampling_weights)\n",
        "    \n",
        "    for pair in idx_pairs:\n",
        "        negatives = []\n",
        "        contexts = pair[1]\n",
        "        center = pair[0]\n",
        "        while len(negatives) <=  K:\n",
        "          \n",
        "            neg = generator.draw()\n",
        "            \n",
        "            # Noise words cannot be context words\n",
        "            if neg not in contexts:\n",
        "              \n",
        "                negatives.append(neg)\n",
        "                \n",
        "        self.negative_pairs.append((center, negatives,0))\n",
        "     \n",
        "    self.negative_pairs = np.array(self.negative_pairs)\n",
        "        \n",
        "    return self.negative_pairs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD6Xw5APKD8k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njWHoCLZV8DO",
        "colab_type": "code",
        "outputId": "616db479-5b74-44a9-d6b6-b14b5837c75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "import random\n",
        "\n",
        "class RandomGenerator(object):\n",
        "    \"\"\"Draw a random int in [0, n] according to n sampling weights\"\"\"\n",
        "    def __init__(self, sampling_weights):\n",
        "        self.population = list(range(len(sampling_weights)))\n",
        "        self.sampling_weights = sampling_weights\n",
        "        self.candidates = []\n",
        "        self.i = 0\n",
        "\n",
        "    def draw(self):\n",
        "        if self.i == len(self.candidates):\n",
        "            self.candidates = random.choices(\n",
        "                self.population, self.sampling_weights, k=10000)\n",
        "            self.i = 0\n",
        "        self.i += 1\n",
        "        return self.candidates[self.i-1]\n",
        "\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "generator = RandomGenerator([2,3,4])\n",
        "[generator.draw() for _ in range(10)]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 0, 2, 1, 0, 2, 2, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLymiuSicQGL",
        "colab_type": "code",
        "outputId": "8c6d1622-4ee8-44b4-96a5-236020617f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#in order to use the dataset from MyDrive, need to mount it in google colab\n",
        "drive.mount('/content/gdrive/')\n",
        "path = '/content/gdrive/My Drive/data/labeledTrainData.tsv'\n",
        "\n",
        "data2 = pd.read_csv(path, header=0, delimiter=\"\\t\", quoting=3)\n",
        "data = data2['review']\n",
        "target = data2['sentiment']\n",
        "\n",
        "data1 = data2.iloc[1:200]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybSrRiltdYO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# create training and testing vars\n",
        "train, test, ytrain, ytest = train_test_split(data, target, test_size=0.2)\n",
        "#print X_train.shape, y_train.shape\n",
        "#print X_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8IIPXlQXy4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = train.values.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPA-qWaOWT2p",
        "colab_type": "code",
        "outputId": "cf1c28e3-036b-40c0-b08d-0074d3cb64be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = []  # Initialize an empty list of sentences\n",
        "vocab =  Creat_vocabulary()\n",
        "sentences =vocab.reviews_to_Words(data1 , tokenizer)\n",
        "\n",
        "vocabulary_size, word2idx, idx2word = vocab.dictionary( tokenizer )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing sentences from training set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umPhbsODV_iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "listofV= vocab.get_sentence()\n",
        "\n",
        "counter = collections.Counter(vocab.expand(listofV))\n",
        "\n",
        "\n",
        "counters = list(counter.values())\n",
        "\n",
        "\n",
        "sampling_weights = [counters[i]**0.75 for i in range(len(counters))]\n",
        "\n",
        "vocab_size = len(counter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gceLeFbPYW46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx_pairs = vocab.skip_contex_tuple(3)\n",
        "\n",
        "all_negatives = vocab.get_negatives(idx_pairs, sampling_weights, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pV2SHWo6C7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CONTEXT_SIZE = len(all_negatives) + len(idx_pairs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8g53tvD3p13",
        "colab_type": "code",
        "outputId": "5e53f17a-943d-46e5-8e73-304896c27901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "all_negatives"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, list([741, 964, 741]), 0],\n",
              "       [1, list([1961, 65, 3897]), 0],\n",
              "       [2, list([1005, 866, 1818]), 0],\n",
              "       ...,\n",
              "       [3080, list([1415, 141, 6919]), 0],\n",
              "       [0, list([4259, 3386, 132]), 0],\n",
              "       [4010, list([226, 679, 5328]), 0]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86ta_1Nc59jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "\n",
        "class Skipgram(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
        "      \n",
        "        super(Skipgram, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.embed_v = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        self.embed_u = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        \n",
        "        initrange = 0.5 / embedding_dim\n",
        "        self.embed_u.weight.data.uniform_(-initrange, initrange)\n",
        "        self.embed_v.weight.data.uniform_(-0, 0)\n",
        "\n",
        "        \n",
        "        #self.linear1 = nn.Linear(embedding_dim, 128)\n",
        "        #self.linear2 = nn.Linear(128, context_size * vocab_size)\n",
        "        #self.parameters['context_size'] = context_size\n",
        "\n",
        " \n",
        "\n",
        "    def forward(self,center, contexts,negatives):\n",
        "        '''\n",
        "        v = self.embed_v(center)\n",
        "        u = self.embed_u(contexts)\n",
        "        pred = torch.mm(v, u.view(200,1))\n",
        "        log_probs = pred\n",
        "        '''\n",
        "        emb_u =  self.embed_u(center)\n",
        "        emb_v =  self.embed_v(contexts)\n",
        "        \n",
        "        score = torch.mul(emb_u, emb_v).squeeze()\n",
        "        #print(score)\n",
        "        score = torch.sum(score)\n",
        "        score = F.logsigmoid(score)\n",
        "        neg_emb_v = self.embed_v(negatives)\n",
        "        #print(neg_emb_v.size())\n",
        "        #print(negatives)\n",
        "        #print(\"*\")\n",
        "        #print(emb_u.unsqueeze(2).size())\n",
        "        neg_score = torch.bmm(neg_emb_v, emb_u.unsqueeze(2)).squeeze()\n",
        "\n",
        "        #neg_score = torch.mm(neg_emb_v, emb_u.view(-1,1)).squeeze()\n",
        "        neg_score = F.logsigmoid(-1 * neg_score)\n",
        "        \n",
        "        return -1 * (torch.sum(score)+torch.sum(neg_score))\n",
        "       \n",
        "        #return log_probs\n",
        "    \n",
        "    def get_embed_v(self):\n",
        "      \n",
        "        return self.embed_v\n",
        "      \n",
        "      \n",
        "    def get_embed_u(self):\n",
        "      \n",
        "        return self.embed_u\n",
        "    \n",
        "      \n",
        "    def get_similar_tokens(self,query_token, k, embed,word2idx,idx2word):\n",
        "      \n",
        "      \n",
        "        w = embed.weight\n",
        "        x = w[word2idx[query_token]].view(-1,1)\n",
        "        W = torch.transpose(w,0,-1)\n",
        "\n",
        "        \n",
        "        cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "        output = cos(W, x)\n",
        "        print(output.size())\n",
        "\n",
        "        values, indices = torch.topk(output, k=k, dim=0)\n",
        "        indices = indices.data.numpy()\n",
        "        \n",
        "        for i in indices:\n",
        "          print(idx2word[i])\n",
        "          \n",
        "          \n",
        "          \n",
        "\n",
        "losses = []\n",
        "EMBEDDING_DIM = 200\n",
        "CONTEXT_SIZE = len(all_negatives) + len(idx_pairs)\n",
        "#loss_function =nn.BCEWithLogitsLoss()\n",
        "model = Skipgram(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tERdq5UH9BNa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d82fde13-9176-4bcf-f7a1-3dfe289792b9"
      },
      "source": [
        "neg_v = torch.tensor([negatives], dtype=torch.long)\n",
        "context"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[130,   5,   8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyiLqEYH9TWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6defc2c-9a6d-4b8e-bc7d-5e8f26bf9063"
      },
      "source": [
        "a= idx_pairs[i][0] \n",
        "a"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-n7Myc2uAly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "losses= []\n",
        "epoch = 7\n",
        "\n",
        "for e in range(epoch):\n",
        "  \n",
        "  running_loss = 0\n",
        "  \n",
        "\n",
        "  for i in range(0,len(idx_pairs)):\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "    context = [i for i in idx_pairs[i][1] ]\n",
        "    negatives = [i for i in all_negatives[i][1] ]\n",
        "\n",
        "    \n",
        "    context =Variable(torch.tensor([context]))\n",
        "    neg_v = Variable(torch.tensor([negatives], dtype=torch.long))\n",
        "    center = Variable(torch.tensor([idx_pairs[i][0]]))\n",
        "    #print(neg_v)\n",
        "    #print(\"VV\")\n",
        "    optimizer.zero_grad()\n",
        "    loss =model.forward(center, context, neg_v)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "else:\n",
        "  \n",
        "  print(f\"Training loss: {running_loss}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtAOAnnm69ob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0053841-24b4-4c60-9433-8f8fdb5dac41"
      },
      "source": [
        "min(losses)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.772561550140381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUJVQyAjLH1R",
        "colab_type": "code",
        "outputId": "c1f89a8a-be60-4719-c346-b6c43351069b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "\n",
        "'''\n",
        "context_size = 3\n",
        "embedding_dim = 126\n",
        "\n",
        "model = nn.Sequential(\n",
        "    \n",
        "    \n",
        "                      nn.Embedding(vocabulary_size, embedding_dim),\n",
        "                      nn.Linear(embedding_dim,256),\n",
        "                      nn.Linear(256,context_size * vocabulary_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "\n",
        "objective = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "'''\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "losses= []\n",
        "epoch = 4\n",
        "tar = [0,1]\n",
        "target = torch.tensor(tar, dtype=torch.long)\n",
        "#target = target.view(1,-1)\n",
        "for e in range(epoch):\n",
        "  \n",
        "  running_loss = 0\n",
        "\n",
        "  for i in range(0,len(idx_pairs)):\n",
        "    \n",
        "    output =[]\n",
        "    label = []\n",
        "    for context in idx_pairs[i][1]:\n",
        "      \n",
        "        context = torch.tensor([context])\n",
        "        center = torch.tensor([idx_pairs[i][0]])\n",
        "        label1 = torch.tensor([idx_pairs[i][2]])\n",
        "        aa=  model.forward(center, context)\n",
        "        #print(aa)\n",
        "        output.append(aa)\n",
        "        label.append(label1)\n",
        "        \n",
        "        \n",
        "    for negative in all_negatives[i][1]:\n",
        "                      \n",
        "        context = torch.tensor([negative], dtype=torch.long)\n",
        "        center = torch.tensor([all_negatives[i][0]], dtype=torch.long)\n",
        "        #label0 = torch.tensor([all_negatives[i][2]])\n",
        "        label0 = torch.tensor([0])\n",
        "        output.append(model.forward(center, context))\n",
        "        label.append(label0)\n",
        "\n",
        "        \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output = Variable(torch.tensor([output], dtype=torch.float32),requires_grad=True)\n",
        "    labelz = torch.tensor([label], dtype=torch.float32)\n",
        "\n",
        "\n",
        "    loss = loss_function(output,labelz)    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "    running_loss += loss.item()\n",
        "    losses.append(loss.item())\n",
        "        \n",
        "      \n",
        "  else:\n",
        "        print(f\"Training loss: {running_loss}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 255439.17614002866\n",
            "Training loss: 255439.17614002866\n",
            "Training loss: 255439.17614002866\n",
            "Training loss: 255439.17614002866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mLrQrpNNPAv",
        "colab_type": "code",
        "outputId": "df5e6ad3-e78e-4300-c11f-3192f7702d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "word2idx = vocab.get_word2idx()\n",
        "idx2word = vocab.get_idx2word()\n",
        "\n",
        "embed = model.get_embed_u()\n",
        "k= 4\n",
        "query_token = 'man'\n",
        "\n",
        "s = model.get_similar_tokens(query_token, k, embed,word2idx,idx2word)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7120])\n",
            "man\n",
            "crappy\n",
            "bossy\n",
            "fatigue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ov0eEwBNRLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = embed.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13sZTA9ECu9w",
        "colab_type": "code",
        "outputId": "0cd39335-f291-4f75-d255-af1429bcc05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "word2idx[\"hines\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3XdFBqaKtdZ",
        "colab_type": "code",
        "outputId": "0d863935-2247-4496-dbbe-96fe34479603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "idx2word[30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'doing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH4v9Xgl0IZy",
        "colab_type": "code",
        "outputId": "149b18e0-0796-4ce5-80d1-9258b4299301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ss = w[7]\n",
        "ss.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnFRlwSpO3CY",
        "colab_type": "code",
        "outputId": "80ad7066-2c2c-49ae-82ad-af07547307e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2028
        }
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',    level=logging.INFO)\n",
        "\n",
        "def myhashfxn(obj):\n",
        "    return hash(obj) % (2 ** 32)\n",
        "\n",
        "# Set values for various parameters\n",
        "num_features = 400    # Word vector dimensionality                      \n",
        "min_word_count = 60   # Minimum word count                        \n",
        "num_workers = 4       # Number of threads to run in parallel\n",
        "context = 10          # Context window size                                                                                    \n",
        "downsampling = 1e-3   # Downsample setting for frequent words\n",
        "\n",
        "\n",
        "#**********************************************************\n",
        "\n",
        "\n",
        "\n",
        "# Initialize and train the model (this will take some time)\n",
        "from gensim.models import word2vec\n",
        "#model = word2vec.Word2Vec(hashfxn=myhashfxn)\n",
        "\n",
        "print (\"Training model...\")\n",
        "model = word2vec.Word2Vec(sentences, workers=num_workers,             size=num_features, min_count = min_word_count,             window = context, sample = downsampling,hashfxn=myhashfxn)\n",
        "\n",
        "# If you don't plan to train the model any further, calling \n",
        "# init_sims will make the model much more memory-efficient.\n",
        "model.init_sims(replace=True)\n",
        "\n",
        "# It can be helpful to create a meaningful model name and \n",
        "# save the model for later use. You can load it later using Word2Vec.load()\n",
        "model_name = \"300features_40minwords_10context\"\n",
        "model.save(model_name)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-06 02:15:44,719 : INFO : 'pattern' package not found; tag filters are not available for English\n",
            "2019-06-06 02:15:44,729 : INFO : collecting all words and their counts\n",
            "2019-06-06 02:15:44,730 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-06-06 02:15:44,786 : INFO : PROGRESS: at sentence #10000, processed 225803 words, keeping 17776 word types\n",
            "2019-06-06 02:15:44,845 : INFO : PROGRESS: at sentence #20000, processed 451892 words, keeping 24948 word types\n",
            "2019-06-06 02:15:44,901 : INFO : PROGRESS: at sentence #30000, processed 671315 words, keeping 30034 word types\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-06 02:15:44,963 : INFO : PROGRESS: at sentence #40000, processed 897815 words, keeping 34348 word types\n",
            "2019-06-06 02:15:45,019 : INFO : PROGRESS: at sentence #50000, processed 1116963 words, keeping 37761 word types\n",
            "2019-06-06 02:15:45,073 : INFO : PROGRESS: at sentence #60000, processed 1338404 words, keeping 40723 word types\n",
            "2019-06-06 02:15:45,127 : INFO : PROGRESS: at sentence #70000, processed 1561580 words, keeping 43333 word types\n",
            "2019-06-06 02:15:45,181 : INFO : PROGRESS: at sentence #80000, processed 1780887 words, keeping 45714 word types\n",
            "2019-06-06 02:15:45,235 : INFO : PROGRESS: at sentence #90000, processed 2004996 words, keeping 48135 word types\n",
            "2019-06-06 02:15:45,289 : INFO : PROGRESS: at sentence #100000, processed 2226966 words, keeping 50207 word types\n",
            "2019-06-06 02:15:45,342 : INFO : PROGRESS: at sentence #110000, processed 2446580 words, keeping 52081 word types\n",
            "2019-06-06 02:15:45,397 : INFO : PROGRESS: at sentence #120000, processed 2668775 words, keeping 54119 word types\n",
            "2019-06-06 02:15:45,452 : INFO : PROGRESS: at sentence #130000, processed 2894303 words, keeping 55847 word types\n",
            "2019-06-06 02:15:45,504 : INFO : PROGRESS: at sentence #140000, processed 3107005 words, keeping 57346 word types\n",
            "2019-06-06 02:15:45,558 : INFO : PROGRESS: at sentence #150000, processed 3332627 words, keeping 59055 word types\n",
            "2019-06-06 02:15:45,613 : INFO : PROGRESS: at sentence #160000, processed 3555315 words, keeping 60617 word types\n",
            "2019-06-06 02:15:45,666 : INFO : PROGRESS: at sentence #170000, processed 3778655 words, keeping 62077 word types\n",
            "2019-06-06 02:15:45,718 : INFO : PROGRESS: at sentence #180000, processed 3999236 words, keeping 63496 word types\n",
            "2019-06-06 02:15:45,771 : INFO : PROGRESS: at sentence #190000, processed 4224449 words, keeping 64794 word types\n",
            "2019-06-06 02:15:45,828 : INFO : PROGRESS: at sentence #200000, processed 4448603 words, keeping 66087 word types\n",
            "2019-06-06 02:15:45,881 : INFO : PROGRESS: at sentence #210000, processed 4669967 words, keeping 67390 word types\n",
            "2019-06-06 02:15:45,934 : INFO : PROGRESS: at sentence #220000, processed 4894968 words, keeping 68697 word types\n",
            "2019-06-06 02:15:45,988 : INFO : PROGRESS: at sentence #230000, processed 5117545 words, keeping 69958 word types\n",
            "2019-06-06 02:15:46,042 : INFO : PROGRESS: at sentence #240000, processed 5345050 words, keeping 71167 word types\n",
            "2019-06-06 02:15:46,097 : INFO : PROGRESS: at sentence #250000, processed 5559165 words, keeping 72351 word types\n",
            "2019-06-06 02:15:46,151 : INFO : PROGRESS: at sentence #260000, processed 5779146 words, keeping 73478 word types\n",
            "2019-06-06 02:15:46,188 : INFO : collected 74218 word types from a corpus of 5920724 raw words and 266551 sentences\n",
            "2019-06-06 02:15:46,189 : INFO : Loading a fresh vocabulary\n",
            "2019-06-06 02:15:46,239 : INFO : effective_min_count=60 retains 6278 unique words (8% of original 74218, drops 67940)\n",
            "2019-06-06 02:15:46,240 : INFO : effective_min_count=60 leaves 5461149 word corpus (92% of original 5920724, drops 459575)\n",
            "2019-06-06 02:15:46,261 : INFO : deleting the raw counts dictionary of 74218 items\n",
            "2019-06-06 02:15:46,264 : INFO : sample=0.001 downsamples 50 most-common words\n",
            "2019-06-06 02:15:46,265 : INFO : downsampling leaves estimated 3933998 word corpus (72.0% of prior 5461149)\n",
            "2019-06-06 02:15:46,282 : INFO : estimated required memory for 6278 words and 400 dimensions: 23228600 bytes\n",
            "2019-06-06 02:15:46,282 : INFO : resetting layer weights\n",
            "2019-06-06 02:15:46,365 : INFO : training model with 4 workers on 6278 vocabulary and 400 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
            "2019-06-06 02:15:47,385 : INFO : EPOCH 1 - PROGRESS: at 10.38% examples, 406628 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:48,408 : INFO : EPOCH 1 - PROGRESS: at 21.29% examples, 413575 words/s, in_qsize 7, out_qsize 1\n",
            "2019-06-06 02:15:49,410 : INFO : EPOCH 1 - PROGRESS: at 32.44% examples, 421396 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:50,432 : INFO : EPOCH 1 - PROGRESS: at 43.62% examples, 423259 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:51,464 : INFO : EPOCH 1 - PROGRESS: at 54.97% examples, 424817 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:52,484 : INFO : EPOCH 1 - PROGRESS: at 66.10% examples, 425588 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:53,492 : INFO : EPOCH 1 - PROGRESS: at 77.17% examples, 426817 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:54,514 : INFO : EPOCH 1 - PROGRESS: at 87.80% examples, 425321 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:55,526 : INFO : EPOCH 1 - PROGRESS: at 99.28% examples, 426877 words/s, in_qsize 5, out_qsize 0\n",
            "2019-06-06 02:15:55,543 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-06 02:15:55,556 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-06 02:15:55,571 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-06 02:15:55,572 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-06 02:15:55,573 : INFO : EPOCH - 1 : training on 5920724 raw words (3934036 effective words) took 9.2s, 427695 effective words/s\n",
            "2019-06-06 02:15:56,590 : INFO : EPOCH 2 - PROGRESS: at 10.55% examples, 415013 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:57,597 : INFO : EPOCH 2 - PROGRESS: at 21.61% examples, 425098 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:58,603 : INFO : EPOCH 2 - PROGRESS: at 32.44% examples, 423699 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:15:59,616 : INFO : EPOCH 2 - PROGRESS: at 43.78% examples, 427531 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:00,655 : INFO : EPOCH 2 - PROGRESS: at 54.79% examples, 425298 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:01,651 : INFO : EPOCH 2 - PROGRESS: at 65.75% examples, 426312 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:02,657 : INFO : EPOCH 2 - PROGRESS: at 76.66% examples, 426679 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:03,666 : INFO : EPOCH 2 - PROGRESS: at 87.48% examples, 426696 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:04,667 : INFO : EPOCH 2 - PROGRESS: at 98.77% examples, 427844 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:04,722 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-06 02:16:04,730 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-06 02:16:04,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-06 02:16:04,751 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-06 02:16:04,752 : INFO : EPOCH - 2 : training on 5920724 raw words (3933412 effective words) took 9.2s, 429040 effective words/s\n",
            "2019-06-06 02:16:05,813 : INFO : EPOCH 3 - PROGRESS: at 10.71% examples, 403540 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:06,828 : INFO : EPOCH 3 - PROGRESS: at 21.95% examples, 419890 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:07,843 : INFO : EPOCH 3 - PROGRESS: at 32.76% examples, 419402 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-06 02:16:08,848 : INFO : EPOCH 3 - PROGRESS: at 43.95% examples, 423435 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:09,852 : INFO : EPOCH 3 - PROGRESS: at 54.97% examples, 424708 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:10,852 : INFO : EPOCH 3 - PROGRESS: at 65.75% examples, 424771 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:11,867 : INFO : EPOCH 3 - PROGRESS: at 77.00% examples, 426643 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:12,878 : INFO : EPOCH 3 - PROGRESS: at 87.47% examples, 424886 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:13,884 : INFO : EPOCH 3 - PROGRESS: at 98.77% examples, 426053 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:13,941 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-06 02:16:13,951 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-06 02:16:13,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-06 02:16:13,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-06 02:16:13,978 : INFO : EPOCH - 3 : training on 5920724 raw words (3933779 effective words) took 9.2s, 426823 effective words/s\n",
            "2019-06-06 02:16:14,994 : INFO : EPOCH 4 - PROGRESS: at 10.71% examples, 421947 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-06 02:16:16,005 : INFO : EPOCH 4 - PROGRESS: at 21.45% examples, 420339 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:17,043 : INFO : EPOCH 4 - PROGRESS: at 32.76% examples, 423055 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:18,064 : INFO : EPOCH 4 - PROGRESS: at 44.10% examples, 426267 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:19,067 : INFO : EPOCH 4 - PROGRESS: at 55.28% examples, 428252 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:20,097 : INFO : EPOCH 4 - PROGRESS: at 66.59% examples, 428933 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:21,104 : INFO : EPOCH 4 - PROGRESS: at 77.65% examples, 429764 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:22,126 : INFO : EPOCH 4 - PROGRESS: at 88.82% examples, 430430 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:23,091 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-06 02:16:23,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-06 02:16:23,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-06 02:16:23,099 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-06 02:16:23,103 : INFO : EPOCH - 4 : training on 5920724 raw words (3934080 effective words) took 9.1s, 431598 effective words/s\n",
            "2019-06-06 02:16:24,118 : INFO : EPOCH 5 - PROGRESS: at 10.71% examples, 423774 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:25,124 : INFO : EPOCH 5 - PROGRESS: at 21.64% examples, 425588 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-06 02:16:26,128 : INFO : EPOCH 5 - PROGRESS: at 32.60% examples, 427180 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:27,145 : INFO : EPOCH 5 - PROGRESS: at 43.78% examples, 428214 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:28,167 : INFO : EPOCH 5 - PROGRESS: at 55.12% examples, 429527 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:29,178 : INFO : EPOCH 5 - PROGRESS: at 66.26% examples, 430095 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:30,181 : INFO : EPOCH 5 - PROGRESS: at 77.17% examples, 430142 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:31,192 : INFO : EPOCH 5 - PROGRESS: at 88.31% examples, 431210 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-06 02:16:32,184 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-06 02:16:32,198 : INFO : EPOCH 5 - PROGRESS: at 99.65% examples, 431646 words/s, in_qsize 2, out_qsize 1\n",
            "2019-06-06 02:16:32,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-06 02:16:32,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-06 02:16:32,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-06 02:16:32,215 : INFO : EPOCH - 5 : training on 5920724 raw words (3933706 effective words) took 9.1s, 432312 effective words/s\n",
            "2019-06-06 02:16:32,216 : INFO : training on a 29603620 raw words (19669013 effective words) took 45.8s, 428987 effective words/s\n",
            "2019-06-06 02:16:32,217 : INFO : precomputing L2-norms of word weight vectors\n",
            "2019-06-06 02:16:32,267 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
            "2019-06-06 02:16:32,268 : INFO : not storing attribute vectors_norm\n",
            "2019-06-06 02:16:32,270 : INFO : not storing attribute cum_table\n",
            "2019-06-06 02:16:32,271 : WARNING : this function is deprecated, use smart_open.open instead\n",
            "2019-06-06 02:16:32,510 : INFO : saved 300features_40minwords_10context\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRHjnKP3O2-1",
        "colab_type": "code",
        "outputId": "94622392-c3b1-44af-9395-b5f3fd0d9149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "model.doesnt_match(\"man woman child kitchen\".split())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kitchen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HrctvxdO26f",
        "colab_type": "code",
        "outputId": "d806b3e5-8cdc-4553-980b-bec741f50c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "\n",
        "model.most_similar(\"man\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.6654655933380127),\n",
              " ('doctor', 0.6339104175567627),\n",
              " ('boy', 0.6286064982414246),\n",
              " ('journalist', 0.594315767288208),\n",
              " ('businessman', 0.5905495285987854),\n",
              " ('lady', 0.5899538397789001),\n",
              " ('guy', 0.5748952627182007),\n",
              " ('soldier', 0.5712598562240601),\n",
              " ('scientist', 0.5709996223449707),\n",
              " ('priest', 0.5663358569145203)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jujvNDbPKve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vector Averaging\n",
        "import numpy as np # Make sure that numpy is imported\n",
        "def makeFeatureVec(words, model, num_features):\n",
        "# Function to average all of the word vectors in a given\n",
        "# paragraph\n",
        "#\n",
        "# Pre-initialize an empty numpy array (for speed)\n",
        "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
        "#\n",
        "    nwords = 0.\n",
        "#\n",
        "# Index2word is a list that contains the names of the words in\n",
        "# the model's vocabulary. Convert it to a set, for speed\n",
        "    index2word_set = set(model.wv.index2word)\n",
        "#\n",
        "# Loop over each word in the review and, if it is in the model's\n",
        "# vocaublary, add its feature vector to the total\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            nwords = nwords + 1.\n",
        "            featureVec = np.add(featureVec,model[word])\n",
        "#\n",
        "# Divide the result by the number of words to get the average\n",
        "    featureVec = np.divide(featureVec,nwords)\n",
        "    return featureVec\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c058MlCUPK3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getAvgFeatureVecs(reviews, model, num_features):\n",
        "# Given a set of reviews (each one a list of words), calculate\n",
        "# the average feature vector for each one and return a 2D numpy array\n",
        "#\n",
        "# Initialize a counter\n",
        "    counter = 0\n",
        "#\n",
        "# Preallocate a 2D numpy array, for speed\n",
        "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
        "# Loop through the reviews\n",
        "    for review in reviews:\n",
        "        if counter%1000 == 0:\n",
        "            print (\"Review %d of %d\" % (counter, len(reviews)))\n",
        "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
        "#\n",
        "# Increment the counter\n",
        "        counter = counter + 1\n",
        "    return reviewFeatureVecs\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjB4MMtqPLCN",
        "colab_type": "code",
        "outputId": "cfee0286-78b8-4ef6-9f2a-f8fe52a82d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "clean_train_reviews = []\n",
        "for review in train1:\n",
        "    clean_train_reviews.append( review_to_wordlist( review,         remove_stopwords=True ))\n",
        "    \n",
        "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
        "print (\"Creating average feature vecs for test reviews\")\n",
        "clean_test_reviews = []\n",
        "for review in test1:\n",
        "    clean_test_reviews.append( review_to_wordlist( review,         remove_stopwords=True ))\n",
        "\n",
        "\n",
        "# In[52]:"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-ad58fd9a1297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclean_train_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mclean_train_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreview_to_wordlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainDataVecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAvgFeatureVecs\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mclean_train_reviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajbzoLmrPK_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expand(lll):\n",
        "  s = []\n",
        "  for ll in lll:\n",
        "    for l in ll:\n",
        "      s.append(l)\n",
        "  return s   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DHiVhllPK0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = [[1],[2,3],[4],[5],[5,5],[5],[5]]\n",
        "\n",
        "q = expand(l)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiQPe8kYd8tc",
        "colab_type": "code",
        "outputId": "ff5754d4-8944-433b-ca6c-0a6f87c2e0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 5, 5, 5, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDoM4k_bPKyo",
        "colab_type": "code",
        "outputId": "254610f6-0e82-4cec-e069-04c198483c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "l = [[1],[2,3],[4],[5],[5,5],[5],[5]]\n",
        "q = expand(l)\n",
        "\n",
        "collections.Counter(q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 1, 2: 1, 3: 1, 4: 1, 5: 5})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3difQDQudksi",
        "colab_type": "code",
        "outputId": "b4c0bd3c-4050-45a5-ca73-d2ba41c1de12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "x0 = torch.randn(3, 4)\n",
        "x = nn.LogSoftmax(dim=1)(x0)\n",
        "x0, x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.5353,  0.3086, -2.6271,  1.6892],\n",
              "         [ 1.2561,  0.1278,  0.1149,  0.2243],\n",
              "         [ 0.1907, -0.0590,  0.6862, -0.7516]]),\n",
              " tensor([[-3.4904, -1.6464, -4.5822, -0.2659],\n",
              "         [-0.6928, -1.8211, -1.8340, -1.7246],\n",
              "         [-1.3376, -1.5873, -0.8422, -2.2800]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in88bM4EwK39",
        "colab_type": "code",
        "outputId": "2fc36fae-8595-4483-9769-17482c6ab86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhBo3RYzfR5f",
        "colab_type": "code",
        "outputId": "dbd48b01-17d2-4f38-95f0-d1f55832314f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y = torch.tensor([1.2, 2.3,3.3,5], dtype=torch.float32)\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2000, 2.3000, 3.3000, 5.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iBvO8kKfTnn",
        "colab_type": "code",
        "outputId": "d4f7a450-efc2-4762-dffb-43464db9162e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-62c248eb0911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1863\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected 2 or more dimensions (got {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1867\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2 or more dimensions (got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfd1YxBofVMz",
        "colab_type": "code",
        "outputId": "92a85bf5-1f3d-41b9-9749-45793abf6352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPV5FKJxfYsy",
        "colab_type": "code",
        "outputId": "54b2b5c9-60ae-46b3-8991-7af8d61f83c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g12pBt-YfdAh",
        "colab_type": "code",
        "outputId": "8b0d43a6-b16a-4dfc-9637-366e87da1f4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEc8JhFosBoY",
        "colab_type": "code",
        "outputId": "58f54d6a-4926-486d-cb36-db8be03fb93d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x[:,:,None].size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R94plPHEAICF",
        "colab_type": "code",
        "outputId": "9a8bf47b-efba-4023-8649-66a8a37f8cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "W = torch.randn(3, 4)\n",
        "W"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0749,  1.1305, -1.6960,  0.6326],\n",
              "        [-0.4664,  0.2873,  0.0303,  0.8147],\n",
              "        [-0.6050,  1.6914, -0.3439, -0.4138]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_1NZ090Aqd9",
        "colab_type": "code",
        "outputId": "9b117186-e889-489d-de55-18bfe4508512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y = torch.tensor([1.2, 2.3,3.3,5], dtype=torch.float32)\n",
        "\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2000, 2.3000, 3.3000, 5.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C530bxh5CO2q",
        "colab_type": "code",
        "outputId": "d0cca45a-ab50-4359-a0cb-45c57cfd93a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "W = torch.tensor([[ 0.0749,  1.1305, -1.6960,  0.0],\n",
        "        [-0.4664,  0.2873,  0.0303,  0.0],\n",
        "        [-0.6050,  1.6914, -0.3439, 0.0]], dtype=torch.float32)\n",
        "W"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0749,  1.1305, -1.6960,  0.0000],\n",
              "        [-0.4664,  0.2873,  0.0303,  0.0000],\n",
              "        [-0.6050,  1.6914, -0.3439,  0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4RxxrVZsEvj",
        "colab_type": "code",
        "outputId": "7ada1cfd-9b1f-4e32-df37-a425878da2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.max(x0,0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([1.6308, 2.2339, 1.5731, 0.5754]), indices=tensor([2, 2, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY34xZH1AKy7",
        "colab_type": "code",
        "outputId": "c2024e50-1937-4182-fbc7-3aa82a8ab915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
        "output = cos(W,y)\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2386,  0.5331, -0.5869,  0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cRsmKsGAxru",
        "colab_type": "code",
        "outputId": "8e61505b-a8b2-4756-d738-559aa24f876a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output = cos(W,y )\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2386,  0.5331, -0.5869,  0.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1FOtjWWBgkj",
        "colab_type": "code",
        "outputId": "609b335c-aa8c-44e4-ae06-f3f67edb1ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = torch.transpose(W,0,-1)\n",
        "s.size()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X79GzjPqDJev",
        "colab_type": "code",
        "outputId": "6a099d7a-b3b0-42c6-e57e-8f15703fcd95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "z = torch.transpose(y.view(-1,1),0,-1)\n",
        "z.size()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd3bbmjKMJ8g",
        "colab_type": "code",
        "outputId": "37ee7c81-3b16-4d56-b954-9da4e0a0c1de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "o = cos(z,W )\n",
        "o.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJF8ES21D5iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values, indices = torch.topk(output, k=3, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVbXgBw2FwzU",
        "colab_type": "code",
        "outputId": "2049b65a-29f8-46c0-e284-66367aae4d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.5133,  0.0000, -1.1611])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naIVp29zGCnl",
        "colab_type": "code",
        "outputId": "ec054fd2-376c-4a73-95ad-8600c366702b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "indices.data.numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaoJ1x1-LBEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}